import { embed } from "./embedding.ts";
import { splitChunks } from "./generation.ts";
import elizaLogger from "./logger.ts";
import {
    type IAgentRuntime,
    type IRAGKnowledgeManager,
    type RAGKnowledgeItem,
    type UUID,
    KnowledgeScope,
} from "./types.ts";
import { stringToUuid } from "./uuid.ts";
import { existsSync } from "fs";
import { join, extname } from "path";
import { readFile } from "fs/promises";

export class RAGKnowledgeManager implements IRAGKnowledgeManager {
    runtime: IAgentRuntime;
    tableName: string;
    knowledgeRoot: string;
    private readonly defaultRAGMatchThreshold = 0.69;
    private readonly defaultRAGMatchCount = 7;

    private readonly stopWords = new Set([
        "a", "an", "and", "are", "as", "at", "be", "by", "does", "for",
        "from", "had", "has", "have", "he", "her", "his", "how", "hey",
        "i", "in", "is", "it", "its", "of", "on", "or", "that", "the",
        "this", "to", "was", "what", "when", "where", "which", "who",
        "will", "with", "would", "there", "their", "they", "your", "you"
    ]);

    constructor(opts: {
        tableName: string;
        runtime: IAgentRuntime;
        knowledgeRoot: string;
    }) {
        this.runtime = opts.runtime;
        this.tableName = opts.tableName;
        this.knowledgeRoot = opts.knowledgeRoot;
    }

    private getQueryTerms(query: string): string[] {
        return query
            .toLowerCase()
            .split(" ")
            .filter((term) => term.length > 2)
            .filter((term) => !this.stopWords.has(term));
    }

    private preprocess(content: string): string {
        if (!content || typeof content !== "string") {
            elizaLogger.warn("Invalid input for preprocessing");
            return "";
        }
        return (
            content
                .replace(/```[\s\S]*?```/g, "")
                .replace(/`.*?`/g, "")
                .replace(/#{1,6}\s*(.*)/g, "$1")
                .replace(/!\[(.*?)\]\(.*?\)/g, "$1")
                .replace(/\[(.*?)\]\(.*?\)/g, "$1")
                .replace(/(https?:\/\/)?(www\.)?([^\s]+\.[^\s]+)/g, "$3")
                .replace(/<@[!&]?\d+>/g, "")
                .replace(/<[^>]*>/g, "")
                .replace(/^\s*[-*_]{3,}\s*$/gm, "")
                .replace(/\/\*[\s\S]*?\*\//g, "")
                .replace(/\/\/.*/g, "")
                .replace(/\s+/g, " ")
                .replace(/\n{3,}/g, "\n\n")
                .trim()
                .toLowerCase()
        );
    }

    private hasProximityMatch(text: string, terms: string[]): boolean {
        if (!text || !terms.length) return false;
        const words = text.toLowerCase().split(" ").filter(w => w.length > 0);
        const allPositions = terms.flatMap(term =>
            words.reduce((positions, word, idx) => {
                if (word.includes(term)) positions.push(idx);
                return positions;
            }, [] as number[])
        ).sort((a, b) => a - b);
        if (allPositions.length < 2) return false;
        for (let i = 0; i < allPositions.length - 1; i++) {
            if (Math.abs(allPositions[i] - allPositions[i + 1]) <= 5) {
                elizaLogger.debug("[Proximity Match]", {
                    terms,
                    positions: allPositions,
                    matchFound: `${allPositions[i]} - ${allPositions[i + 1]}`
                });
                return true;
            }
        }
        return false;
    }

    async getKnowledge(params: {
        query?: string;
        id?: UUID;
        conversationContext?: string;
        limit?: number;
        agentId?: UUID;
    }): Promise<RAGKnowledgeItem[]> {
        const agentId = params.agentId || this.runtime.agentId;

        if (params.id) {
            elizaLogger.debug(`[RAG Query] Direct lookup by ID: ${params.id}, agentId: ${agentId}`);
            const directResults = await this.runtime.databaseAdapter.getKnowledge({
                id: params.id,
                agentId: agentId,
            });
            if (directResults.length > 0) {
                elizaLogger.info(`[RAG Result] Found ${directResults.length} items for ID: ${params.id}`, {
                    items: directResults.map(item => ({
                        id: item.id,
                        text: item.content.text.slice(0, 100),
                        metadata: item.content.metadata,
                    })),
                });
                return directResults;
            } else {
                elizaLogger.info(`[RAG Result] No items found for ID: ${params.id}`);
            }
        }

        if (params.query) {
            try {
                elizaLogger.info(`[RAG Query] Performing semantic search`, {
                    query: params.query,
                    conversationContext: params.conversationContext?.slice(0, 200) || "none",
                    limit: params.limit || this.defaultRAGMatchCount,
                    agentId,
                });
                const processedQuery = this.preprocess(params.query);
                elizaLogger.debug(`[RAG Query] Processed query: ${processedQuery}`);

                let searchText = processedQuery;
                if (params.conversationContext) {
                    const relevantContext = this.preprocess(params.conversationContext);
                    searchText = `${relevantContext} ${processedQuery}`;
                    elizaLogger.debug(`[RAG Query] Search text with context: ${searchText.slice(0, 200)}`);
                }

                const embeddingArray = await embed(this.runtime, searchText);
                elizaLogger.debug(`[RAG Query] Generated embedding for search text`);

                const embedding = new Float32Array(embeddingArray);

                const results = await this.runtime.databaseAdapter.searchKnowledge({
                    agentId: this.runtime.agentId,
                    embedding: embedding,
                    match_threshold: this.defaultRAGMatchThreshold,
                    match_count: (params.limit || this.defaultRAGMatchCount) * 2,
                    searchText: processedQuery,
                });

                elizaLogger.info(`[RAG Result] Retrieved ${results.length} items for query: ${params.query}`, {
                    items: results.map(item => ({
                        id: item.id,
                        text: item.content.text.slice(0, 100),
                        similarity: item.similarity,
                        metadata: item.content.metadata,
                    })),
                });

                const rerankedResults = results
                    .map((result) => {
                        let score = result.similarity;
                        const queryTerms = this.getQueryTerms(processedQuery);
                        const matchingTerms = queryTerms.filter((term) =>
                            result.content.text.toLowerCase().includes(term)
                        );

                        if (matchingTerms.length > 0) {
                            score *= 1 + (matchingTerms.length / queryTerms.length) * 1.5;
                            if (this.hasProximityMatch(result.content.text, matchingTerms)) {
                                score *= 1.2;
                            }
                            elizaLogger.debug(`[RAG Rerank] Item ${result.id} score adjusted`, {
                                originalSimilarity: result.similarity,
                                newScore: score,
                                matchingTerms,
                            });
                        } // Removed penalty to avoid filtering out relevant items

                        return {
                            ...result,
                            score,
                            matchedTerms: matchingTerms,
                        };
                    })
                    .sort((a, b) => b.score - a.score);

                elizaLogger.info(`[RAG Rerank] Reranked ${rerankedResults.length} items`, {
                    items: rerankedResults.map(item => ({
                        id: item.id,
                        text: item.content.text.slice(0, 100),
                        score: item.score,
                        matchedTerms: item.matchedTerms,
                    })),
                });

                return rerankedResults
                    .filter((result) => result.score >= this.defaultRAGMatchThreshold)
                    .slice(0, params.limit || this.defaultRAGMatchCount);
            } catch (error) {
                elizaLogger.error(`[RAG Search Error] ${error}`);
                return [];
            }
        }

        return [];
    }

    async createKnowledge(item: RAGKnowledgeItem): Promise<void> {
        if (!item.content.text) {
            elizaLogger.warn("Empty content in knowledge item");
            return;
        }

        try {
            await this.runtime.databaseAdapter.db.transaction(async () => {
                // Check for existing knowledge
                const existing = await this.runtime.databaseAdapter.getKnowledge({
                    id: item.id,
                    agentId: this.runtime.agentId,
                });

                if (existing.length > 0 && existing[0].content.text !== item.content.text) {
                    await this.removeKnowledge(item.id);
                    elizaLogger.info(`[Knowledge Update] Removed existing knowledge ${item.id} due to content change`);
                }

                // Process main document
                const processedContent = this.preprocess(item.content.text);
                const mainEmbeddingArray = await embed(this.runtime, processedContent);
                const mainEmbedding = new Float32Array(mainEmbeddingArray);

                // Create main document
                await this.runtime.databaseAdapter.createKnowledge({
                    id: item.id,
                    agentId: item.content.metadata?.isShared ? null : this.runtime.agentId,
                    content: {
                        text: item.content.text,
                        metadata: {
                            ...item.content.metadata,
                            isMain: true,
                        },
                    },
                    embedding: mainEmbedding,
                    createdAt: Date.now(),
                });

                // Generate and store chunks
                const chunks = await splitChunks(processedContent, 512, 20);
                for (const [index, chunk] of chunks.entries()) {
                    const chunkEmbeddingArray = await embed(this.runtime, chunk);
                    const chunkEmbedding = new Float32Array(chunkEmbeddingArray);
                    const chunkId = `${item.id}-chunk-${index}` as UUID;

                    await this.runtime.databaseAdapter.createKnowledge({
                        id: chunkId,
                        agentId: item.content.metadata?.isShared ? null : this.runtime.agentId,
                        content: {
                            text: chunk,
                            metadata: {
                                ...item.content.metadata,
                                isChunk: true,
                                originalId: item.id,
                                chunkIndex: index,
                            },
                        },
                        embedding: chunkEmbedding,
                        createdAt: Date.now(),
                    });
                }

                elizaLogger.info(`[Knowledge Create] Created knowledge ${item.id} with ${chunks.length} chunks`);
            })();
        } catch (error) {
            if (error?.code === "SQLITE_CONSTRAINT_PRIMARYKEY") {
                elizaLogger.info(`Knowledge ${item.id} already exists, skipping creation`);
                return;
            }
            elizaLogger.error(`Error processing knowledge ${item.id}:`, error);
            throw error;
        }
    }

    async removeKnowledge(id: UUID): Promise<void> {
        try {
            await this.runtime.databaseAdapter.db.transaction(async () => {
                // Get chunks associated with the main document
                const allKnowledge = await this.listAllKnowledge(this.runtime.agentId);
                const chunks = allKnowledge.filter(item =>
                    item.content.metadata?.originalId === id && item.content.metadata?.isChunk
                );

                // Delete cache entries for the main document and chunks
                const knowledgeIds = [id, ...chunks.map(chunk => chunk.id)];
                for (const knowledgeId of knowledgeIds) {
                    const cacheKeys = await this.runtime.cacheManager.getCacheKeysForKnowledge({
                        knowledgeId,
                        agentId: this.runtime.agentId,
                    });
                     for (const cacheKey of cacheKeys) {
                        await this.runtime.cacheManager.delete(cacheKey);
                        elizaLogger.info(`[Cache Invalidation] Removed cache key ${cacheKey} for knowledge ${knowledgeId}`);
                    }
                    await this.runtime.cacheManager.removeCacheKeysForKnowledge({
                        knowledgeId,
                        agentId: this.runtime.agentId,
                    });
                }

                // Delete chunks from knowledge table
                for (const chunk of chunks) {
                    await this.runtime.databaseAdapter.removeKnowledge(chunk.id);
                    elizaLogger.debug(`[Knowledge Remove] Removed chunk ${chunk.id}`);
                }

                // Delete main document
                await this.runtime.databaseAdapter.removeKnowledge(id);
                elizaLogger.debug(`[Knowledge Remove] Removed main document ${id}`);
            })();
            elizaLogger.info(`[Knowledge Remove] Successfully removed knowledge ${id} and its chunks`);
        } catch (error) {
            elizaLogger.error(`[Knowledge Remove] Error removing knowledge ${id}:`, error);
            throw error;
        }
    }

    async searchKnowledge(params: {
        agentId: UUID;
        embedding: Float32Array | number[];
        match_threshold?: number;
        match_count?: number;
        searchText?: string;
    }): Promise<RAGKnowledgeItem[]> {
        const {
            match_threshold = this.defaultRAGMatchThreshold,
            match_count = this.defaultRAGMatchCount,
            embedding,
            searchText,
        } = params;

        const float32Embedding = Array.isArray(embedding)
            ? new Float32Array(embedding)
            : embedding;

        return await this.runtime.databaseAdapter.searchKnowledge({
            agentId: params.agentId || this.runtime.agentId,
            embedding: float32Embedding,
            match_threshold,
            match_count,
            searchText,
        });
    }

    async clearKnowledge(shared?: boolean): Promise<void> {
        try {
            // Clear cache_map entries for the agent
            const sql = shared
                ? `DELETE FROM cache_map WHERE agentId = ? OR agentId IS NULL`
                : `DELETE FROM cache_map WHERE agentId = ?`;
            await this.runtime.databaseAdapter.db.prepare(sql).run(this.runtime.agentId);
            elizaLogger.info(`[Cache Invalidation] Cleared cache_map entries for agent ${this.runtime.agentId}`);

            // Clear cache entries
            const cacheSql = shared
                ? `DELETE FROM cache WHERE agentId = ? OR agentId IS NULL`
                : `DELETE FROM cache WHERE agentId = ?`;
            await this.runtime.databaseAdapter.db.prepare(cacheSql).run(this.runtime.agentId);
            elizaLogger.info(`[Cache Invalidation] Cleared cache entries for agent ${this.runtime.agentId}`);

            // Clear knowledge
            await this.runtime.databaseAdapter.clearKnowledge(this.runtime.agentId, shared);
        } catch (error) {
            elizaLogger.error(`Error clearing knowledge for agent ${this.runtime.agentId}:`, error);
            throw error;
        }
    }

    async cleanupCacheMap(): Promise<void> {
        try {
            const oneWeekAgo = Date.now() - 7 * 24 * 60 * 60 * 1000; // 1 week
            const sql = `DELETE FROM cache_map WHERE createdAt < ?`;
            const result = await this.runtime.databaseAdapter.db.prepare(sql).run(oneWeekAgo);
            elizaLogger.info(`[Cache Map Cleanup] Removed ${result.changes} expired cache_map entries`);
        } catch (error) {
            elizaLogger.error(`[Cache Map Cleanup] Error cleaning cache_map:`, error);
        }
    }

    async listAllKnowledge(agentId: UUID): Promise<RAGKnowledgeItem[]> {
        elizaLogger.debug(`[Knowledge List] Fetching all entries for agent: ${agentId}`);
        try {
            const results = await this.runtime.databaseAdapter.getKnowledge({
                agentId: agentId,
            });
            elizaLogger.debug(`[Knowledge List] Found ${results.length} entries`);
            return results;
        } catch (error) {
            elizaLogger.error("[Knowledge List] Error fetching knowledge entries:", error);
            throw error;
        }
    }

    async cleanupDeletedKnowledgeFiles() {
        try {
            elizaLogger.debug("[Cleanup] Starting knowledge cleanup process, agent: ", this.runtime.agentId);
            elizaLogger.debug(`[Cleanup] Knowledge root path: ${this.knowledgeRoot}`);

            const existingKnowledge = await this.listAllKnowledge(this.runtime.agentId);
            const parentDocuments = existingKnowledge.filter(
                (item) => !item.id.includes("chunk") && item.content.metadata?.source
            );

            elizaLogger.debug(`[Cleanup] Found ${parentDocuments.length} parent documents to check`);

            for (const item of parentDocuments) {
                const relativePath = item.content.metadata?.source;
                if (relativePath === "string" || relativePath === "sanity" || relativePath === "sanity-reference") {
                    elizaLogger.debug(`[Cleanup] Skipping non-filesystem knowledge item: ${item.id} (source: ${relativePath})`);
                    continue;
                }

                const filePath = join(this.knowledgeRoot, relativePath);
                elizaLogger.debug(`[Cleanup] Checking joined file path: ${filePath}`);

                if (!existsSync(filePath)) {
                    elizaLogger.warn(`[Cleanup] File not found, starting removal process: ${filePath}`);
                    const idToRemove = item.id;
                    await this.removeKnowledge(idToRemove);
                    elizaLogger.success(`[Cleanup] Successfully removed knowledge for file: ${filePath}`);
                }
            }

            // Clean up expired cache_map entries
            await this.cleanupCacheMap();
            elizaLogger.debug("[Cleanup] Finished knowledge cleanup process");
        } catch (error) {
            elizaLogger.error("[Cleanup] Error cleaning up deleted knowledge files:", error);
        }
    }

    public generateScopedId(path: string, isShared: boolean): UUID {
        const scope = isShared ? KnowledgeScope.SHARED : KnowledgeScope.PRIVATE;
        const scopedPath = `${scope}-${path}`;
        return stringToUuid(scopedPath);
    }

    async addStringKnowledge(content: string, isShared: boolean = false): Promise<void> {
        const knowledgeId = stringToUuid(`${isShared ? "shared" : this.runtime.agentId}-${content.slice(0, 50)}`);
        const existingKnowledge = await this.getKnowledge({ id: knowledgeId });

        if (existingKnowledge.length > 0 && existingKnowledge[0].content.text === content) {
            elizaLogger.info(`String knowledge ${knowledgeId} unchanged, skipping`);
            return;
        }

        await this.createKnowledge({
            id: knowledgeId,
            agentId: this.runtime.agentId,
            content: {
                text: content,
                metadata: {
                    type: "direct",
                    isShared,
                    isMain: true, // Set isMain to true for direct knowledge
                    isChunk: false,
                },
            },
            createdAt: Date.now(),
        });
        elizaLogger.info(`Added string knowledge: ${content.slice(0, 50)}...`);
    }

    async addFileKnowledge(relativePath: string, isShared: boolean): Promise<void> {
        try {
            const ext = extname(relativePath).toLowerCase();
            const fullPath = join(this.knowledgeRoot, relativePath);
            let content: string;
            let type: "txt" | "md";

            if (ext === ".md" || ext === ".txt") {
                content = await readFile(fullPath, "utf-8");
                type = ext === ".md" ? "md" : "txt";
            } else {
                throw new Error(`Unsupported file type: ${ext}`);
            }

            await this.processFile({
                path: relativePath,
                content,
                type,
                isShared,
            });
            elizaLogger.success(`Added file knowledge: ${relativePath}`);
        } catch (error) {
            elizaLogger.error(`Failed to add file knowledge: ${relativePath}`, error);
            throw error;
        }
    }

    async addSanityKnowledge(items: RAGKnowledgeItem[]): Promise<void> {
        try {
            await this.runtime.databaseAdapter.db.transaction(async () => {
                for (const item of items) {
                    const knowledgeId = item.id || stringToUuid(`${this.runtime.agentId}-sanity-${item.content.text.slice(0, 50)}`);
                    const existingKnowledge = await this.getKnowledge({ id: knowledgeId });

                    if (existingKnowledge.length > 0 && existingKnowledge[0].content.text === item.content.text) {
                        elizaLogger.info(`Sanity knowledge: ${knowledgeId} unchanged, skipping`);
                        continue;
                    }

                    let embedding = item.embedding;
                    if (!embedding) {
                        elizaLogger.warn(`No embedding for Sanity item ${knowledgeId}, generating locally`);
                        const embeddingArray = await embed(this.runtime, item.content.text);
                        embedding = new Float32Array(embeddingArray);
                    }

                    await this.createKnowledge({
                        id: knowledgeId,
                        agentId: this.runtime.agentId,
                        content: {
                            text: item.content.text,
                            metadata: {
                                type: item.content.metadata?.type || "text",
                                isShared: item.content.metadata?.isShared || false,
                                source: "sanity-reference",
                                isMain: true, // Set isMain to true for Sanity items
                                isChunk: item.content.metadata?.isChunk || false,
                                originalId: item.content.metadata?.originalId,
                                chunkIndex: item.content.metadata?.chunkIndex,
                                category: item.content.metadata?.category || "",
                                customFields: item.content.metadata?.customFields || [],
                            },
                        },
                        embedding,
                        createdAt: item.createdAt || Date.now(),
                    });
                    elizaLogger.info(`Added Sanity knowledge: ${item.content.text.slice(0, 50)}...`);
                }
            })();
        } catch (error) {
            elizaLogger.error(`Error adding Sanity knowledge:`, error);
            throw error;
        }
    }

    async processFile(file: {
        path: string;
        content: string;
        type: "pdf" | "md" | "txt";
        isShared?: boolean;
    }): Promise<void> {
        const timeMarker = (label: string) => {
            const time = (Date.now() - startTime) / 1000;
            elizaLogger.info(`[Timing] ${label}: ${time.toFixed(2)}s`);
        };

        const startTime = Date.now();
        const content = file.content;

        try {
            await this.runtime.databaseAdapter.db.transaction(async () => {
                const fileSizeKB = new TextEncoder().encode(content).length / 1024;
                elizaLogger.info(`[File Progress] Starting ${file.path} (${fileSizeKB.toFixed(2)} KB)`);

                const scopedId = this.generateScopedId(file.path, file.isShared || false);
                const existingKnowledge = await this.getKnowledge({ id: scopedId });

                if (existingKnowledge.length > 0 && existingKnowledge[0].content.text === content) {
                    elizaLogger.info(`Knowledge ${file.path} unchanged, skipping`);
                    return;
                }

                if (existingKnowledge.length > 0) {
                    await this.removeKnowledge(scopedId);
                    elizaLogger.info(`[processFile] Removed existing knowledge ${scopedId} due to content change`);
                }

                const processedContent = this.preprocess(content);
                timeMarker("Preprocessing");

                const mainEmbeddingArray = await embed(this.runtime, processedContent);
                const mainEmbedding = new Float32Array(mainEmbeddingArray);
                timeMarker("Main embedding");

                await this.runtime.databaseAdapter.createKnowledge({
                    id: scopedId,
                    agentId: file.isShared ? null : this.runtime.agentId,
                    content: {
                        text: content,
                        metadata: {
                            source: file.path,
                            type: file.type,
                            isShared: file.isShared || false,
                            isMain: true,
                        },
                    },
                    embedding: mainEmbedding,
                    createdAt: Date.now(),
                });
                timeMarker("Main document storage");

                const chunks = await splitChunks(processedContent, 512, 20);
                const totalChunks = chunks.length;
                elizaLogger.info(`Generated ${totalChunks} chunks`);
                timeMarker("Chunk generation");

                const BATCH_SIZE = 10;
                let processedChunks = 0;

                for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
                    const batchStart = Date.now();
                    const batch = chunks.slice(i, Math.min(i + BATCH_SIZE, chunks.length));

                    const embeddings = await Promise.all(
                        batch.map((chunk) => embed(this.runtime, chunk))
                    );

                    await Promise.all(
                        embeddings.map(async (embeddingArray, index) => {
                            const chunkId = `${scopedId}-chunk-${i + index}` as UUID;
                            const chunkEmbedding = new Float32Array(embeddingArray);

                            await this.runtime.databaseAdapter.createKnowledge({
                                id: chunkId,
                                agentId: file.isShared ? null : this.runtime.agentId,
                                content: {
                                    text: batch[index],
                                    metadata: {
                                        source: file.path,
                                        type: file.type,
                                        isShared: file.isShared || false,
                                        isChunk: true,
                                        originalId: scopedId,
                                        chunkIndex: i + index,
                                        originalPath: file.path,
                                    },
                                },
                                embedding: chunkEmbedding,
                                createdAt: Date.now(),
                            });
                        })
                    );

                    processedChunks += batch.length;
                    const batchTime = (Date.now() - batchStart) / 1000;
                    elizaLogger.info(
                        `[Batch Progress] ${file.path}: Processed ${processedChunks}/${totalChunks} chunks (${batchTime.toFixed(2)}s for batch)`
                    );
                }

                const totalTime = (Date.now() - startTime) / 1000;
                elizaLogger.info(`[Complete] Processed ${file.path} in ${totalTime.toFixed(2)}s`);
            })();
        } catch (error) {
            if (error?.code === "SQLITE_CONSTRAINT_PRIMARYKEY") {
                elizaLogger.info(`Knowledge ${file.path} already exists in database, skipping creation`);
                return;
            }
            elizaLogger.error(`Error processing file ${file.path}:`, error);
            throw error;
        }
    }
}